{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1a50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd1c7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0  6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1  6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2  6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3  7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4  7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "\n",
       "       CO     NOX  \n",
       "0  3.1547  82.722  \n",
       "1  3.2363  82.776  \n",
       "2  3.2012  82.468  \n",
       "3  3.1923  82.670  \n",
       "4  3.2484  82.311  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine=pd.read_csv(\"C:\\\\Users\\\\ASUS\\\\Downloads\\\\DATA SCIENCE\\\\ASSIGNMENTS\\\\Neural Networks\\\\gas_turbines.csv\")\n",
    "turbine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89879683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb51e968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "turbine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f67202f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134.18846399361655"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we have to convert the TEY column into categorical column so need to calculate the mean first and then using lambda function categorize that column into 0's and 1's according to the mean\n",
    "turbine_mean = turbine.TEY.mean()\n",
    "turbine_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5930e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine['performance'] = turbine.TEY.map(lambda x: 1 if x > 134 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69fc26b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "15034    0\n",
       "15035    0\n",
       "15036    0\n",
       "15037    0\n",
       "15038    0\n",
       "Name: performance, Length: 15039, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7650bcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8484\n",
       "1    6555\n",
       "Name: performance, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.performance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8c5307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  performance  \n",
       "0      3.1547  82.722            0  \n",
       "1      3.2363  82.776            0  \n",
       "2      3.2012  82.468            0  \n",
       "3      3.1923  82.670            0  \n",
       "4      3.2484  82.311            0  \n",
       "...       ...     ...          ...  \n",
       "15034  4.5186  79.559            0  \n",
       "15035  4.8470  79.917            0  \n",
       "15036  7.9632  90.912            0  \n",
       "15037  6.2494  93.227            0  \n",
       "15038  4.9816  92.498            0  \n",
       "\n",
       "[15039 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa28e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine.drop(['TEY'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d73d504b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX  performance  \n",
       "0      82.722            0  \n",
       "1      82.776            0  \n",
       "2      82.468            0  \n",
       "3      82.670            0  \n",
       "4      82.311            0  \n",
       "...       ...          ...  \n",
       "15034  79.559            0  \n",
       "15035  79.917            0  \n",
       "15036  90.912            0  \n",
       "15037  93.227            0  \n",
       "15038  92.498            0  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aef5a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "679c6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into x and y as input and output\n",
    "\n",
    "x= turbine.iloc[:,0:10]\n",
    "y= turbine.iloc[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0ed0571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX  \n",
       "0      82.722  \n",
       "1      82.776  \n",
       "2      82.468  \n",
       "3      82.670  \n",
       "4      82.311  \n",
       "...       ...  \n",
       "15034  79.559  \n",
       "15035  79.917  \n",
       "15036  90.912  \n",
       "15037  93.227  \n",
       "15038  92.498  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12b25f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "15034    0\n",
       "15035    0\n",
       "15036    0\n",
       "15037    0\n",
       "15038    0\n",
       "Name: performance, Length: 15039, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f11ea953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df047d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "781ec220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9aa6f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66864ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b9b219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63f7355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30, 30))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7ee7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train=mlp.predict(x_train)\n",
    "prediction_test = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49a14e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea9dd8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e78bead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2392  148]\n",
      " [ 170 1802]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9391089579177353"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,prediction_test))\n",
    "np.mean(y_test==prediction_test)\n",
    "np.mean(y_train==prediction_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eddfd5",
   "metadata": {},
   "source": [
    "# With  Backpropogation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16ee46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "#pip install keras\n",
    "#https://www.tensorflow.org/install/pip#windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f0a4cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d94c4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b456e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 1.7299 - accuracy: 0.7130 - val_loss: 0.5000 - val_accuracy: 0.7227\n",
      "Epoch 2/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4436 - accuracy: 0.7709 - val_loss: 0.4024 - val_accuracy: 0.7538\n",
      "Epoch 3/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4186 - accuracy: 0.7790 - val_loss: 0.3602 - val_accuracy: 0.7767\n",
      "Epoch 4/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3949 - accuracy: 0.7893 - val_loss: 0.3421 - val_accuracy: 0.8338\n",
      "Epoch 5/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3856 - accuracy: 0.7904 - val_loss: 0.3019 - val_accuracy: 0.8551\n",
      "Epoch 6/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3751 - accuracy: 0.8007 - val_loss: 0.3034 - val_accuracy: 0.8434\n",
      "Epoch 7/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3796 - accuracy: 0.7943 - val_loss: 0.3310 - val_accuracy: 0.8350\n",
      "Epoch 8/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3675 - accuracy: 0.8046 - val_loss: 0.3436 - val_accuracy: 0.8330\n",
      "Epoch 9/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3693 - accuracy: 0.8006 - val_loss: 0.2858 - val_accuracy: 0.8473\n",
      "Epoch 10/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3525 - accuracy: 0.8124 - val_loss: 0.3043 - val_accuracy: 0.8396\n",
      "Epoch 11/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3578 - accuracy: 0.8059 - val_loss: 0.2752 - val_accuracy: 0.8525\n",
      "Epoch 12/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3563 - accuracy: 0.8079 - val_loss: 0.2752 - val_accuracy: 0.9081\n",
      "Epoch 13/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3651 - accuracy: 0.8031 - val_loss: 0.2727 - val_accuracy: 0.8551\n",
      "Epoch 14/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3519 - accuracy: 0.8073 - val_loss: 0.2820 - val_accuracy: 0.8449\n",
      "Epoch 15/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3478 - accuracy: 0.8126 - val_loss: 0.2713 - val_accuracy: 0.9027\n",
      "Epoch 16/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3489 - accuracy: 0.8140 - val_loss: 0.2661 - val_accuracy: 0.8636\n",
      "Epoch 17/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3479 - accuracy: 0.8096 - val_loss: 0.3628 - val_accuracy: 0.8326\n",
      "Epoch 18/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8065 - val_loss: 0.2785 - val_accuracy: 0.8465\n",
      "Epoch 19/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3416 - accuracy: 0.8128 - val_loss: 0.2606 - val_accuracy: 0.8622\n",
      "Epoch 20/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3384 - accuracy: 0.8163 - val_loss: 0.2624 - val_accuracy: 0.8968\n",
      "Epoch 21/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3404 - accuracy: 0.8160 - val_loss: 0.2934 - val_accuracy: 0.8420\n",
      "Epoch 22/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3336 - accuracy: 0.8164 - val_loss: 0.2546 - val_accuracy: 0.8749\n",
      "Epoch 23/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.8213 - val_loss: 0.2582 - val_accuracy: 0.8565\n",
      "Epoch 24/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3384 - accuracy: 0.8155 - val_loss: 0.2656 - val_accuracy: 0.8932\n",
      "Epoch 25/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3374 - accuracy: 0.8173 - val_loss: 0.2572 - val_accuracy: 0.8608\n",
      "Epoch 26/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3424 - accuracy: 0.8140 - val_loss: 0.2595 - val_accuracy: 0.8596\n",
      "Epoch 27/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3321 - accuracy: 0.8204 - val_loss: 0.2552 - val_accuracy: 0.8938\n",
      "Epoch 28/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8139 - val_loss: 0.2567 - val_accuracy: 0.8658\n",
      "Epoch 29/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.8200 - val_loss: 0.2587 - val_accuracy: 0.9109\n",
      "Epoch 30/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3404 - accuracy: 0.8149 - val_loss: 0.2616 - val_accuracy: 0.9113\n",
      "Epoch 31/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3343 - accuracy: 0.8207 - val_loss: 0.2924 - val_accuracy: 0.7909\n",
      "Epoch 32/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3372 - accuracy: 0.8184 - val_loss: 0.2632 - val_accuracy: 0.9128\n",
      "Epoch 33/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3322 - accuracy: 0.8203 - val_loss: 0.2506 - val_accuracy: 0.8642\n",
      "Epoch 34/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8253 - val_loss: 0.2483 - val_accuracy: 0.8783\n",
      "Epoch 35/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.8188 - val_loss: 0.2577 - val_accuracy: 0.8561\n",
      "Epoch 36/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3290 - accuracy: 0.8234 - val_loss: 0.2589 - val_accuracy: 0.9075\n",
      "Epoch 37/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3250 - accuracy: 0.8256 - val_loss: 0.2663 - val_accuracy: 0.8499\n",
      "Epoch 38/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8184 - val_loss: 0.3137 - val_accuracy: 0.7558\n",
      "Epoch 39/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3359 - accuracy: 0.8139 - val_loss: 0.3003 - val_accuracy: 0.8412\n",
      "Epoch 40/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3270 - accuracy: 0.8236 - val_loss: 0.2483 - val_accuracy: 0.8886\n",
      "Epoch 41/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3246 - accuracy: 0.8237 - val_loss: 0.2557 - val_accuracy: 0.9043\n",
      "Epoch 42/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3250 - accuracy: 0.8230 - val_loss: 0.5156 - val_accuracy: 0.8328\n",
      "Epoch 43/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8227 - val_loss: 0.2509 - val_accuracy: 0.8614\n",
      "Epoch 44/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3264 - accuracy: 0.8242 - val_loss: 0.2584 - val_accuracy: 0.8529\n",
      "Epoch 45/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3245 - accuracy: 0.8290 - val_loss: 0.2869 - val_accuracy: 0.8438\n",
      "Epoch 46/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3297 - accuracy: 0.8198 - val_loss: 0.2557 - val_accuracy: 0.9105\n",
      "Epoch 47/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3239 - accuracy: 0.8270 - val_loss: 0.2498 - val_accuracy: 0.8993\n",
      "Epoch 48/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3242 - accuracy: 0.8253 - val_loss: 0.2920 - val_accuracy: 0.7866\n",
      "Epoch 49/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3206 - accuracy: 0.8277 - val_loss: 0.2460 - val_accuracy: 0.9007\n",
      "Epoch 50/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3219 - accuracy: 0.8296 - val_loss: 0.2416 - val_accuracy: 0.8815\n",
      "Epoch 51/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3286 - accuracy: 0.8232 - val_loss: 0.2526 - val_accuracy: 0.8573\n",
      "Epoch 52/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3219 - accuracy: 0.8283 - val_loss: 0.2803 - val_accuracy: 0.8453\n",
      "Epoch 53/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3195 - accuracy: 0.8251 - val_loss: 0.2625 - val_accuracy: 0.8666\n",
      "Epoch 54/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3266 - accuracy: 0.8249 - val_loss: 0.2632 - val_accuracy: 0.8854\n",
      "Epoch 55/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3202 - accuracy: 0.8317 - val_loss: 0.2400 - val_accuracy: 0.8918\n",
      "Epoch 56/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3258 - accuracy: 0.8270 - val_loss: 0.3292 - val_accuracy: 0.8392\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3242 - accuracy: 0.8224 - val_loss: 0.2571 - val_accuracy: 0.8527\n",
      "Epoch 58/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3192 - accuracy: 0.8291 - val_loss: 0.3040 - val_accuracy: 0.8432\n",
      "Epoch 59/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3231 - accuracy: 0.8266 - val_loss: 0.2963 - val_accuracy: 0.8432\n",
      "Epoch 60/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3251 - accuracy: 0.8252 - val_loss: 0.2550 - val_accuracy: 0.8549\n",
      "Epoch 61/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3123 - accuracy: 0.8329 - val_loss: 0.2812 - val_accuracy: 0.8003\n",
      "Epoch 62/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3185 - accuracy: 0.8278 - val_loss: 0.3116 - val_accuracy: 0.8432\n",
      "Epoch 63/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3222 - accuracy: 0.8228 - val_loss: 0.2557 - val_accuracy: 0.8533\n",
      "Epoch 64/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3279 - accuracy: 0.8211 - val_loss: 0.2719 - val_accuracy: 0.8477\n",
      "Epoch 65/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3140 - accuracy: 0.8309 - val_loss: 0.3376 - val_accuracy: 0.7489\n",
      "Epoch 66/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3206 - accuracy: 0.8275 - val_loss: 0.2404 - val_accuracy: 0.8741\n",
      "Epoch 67/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3265 - accuracy: 0.8222 - val_loss: 0.2524 - val_accuracy: 0.9154\n",
      "Epoch 68/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3201 - accuracy: 0.8293 - val_loss: 0.2616 - val_accuracy: 0.8864\n",
      "Epoch 69/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3319 - accuracy: 0.8197 - val_loss: 0.2922 - val_accuracy: 0.8430\n",
      "Epoch 70/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3191 - accuracy: 0.8241 - val_loss: 0.2411 - val_accuracy: 0.8902\n",
      "Epoch 71/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3196 - accuracy: 0.8264 - val_loss: 0.2533 - val_accuracy: 0.8537\n",
      "Epoch 72/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3193 - accuracy: 0.8306 - val_loss: 0.2402 - val_accuracy: 0.8664\n",
      "Epoch 73/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3235 - accuracy: 0.8236 - val_loss: 0.2459 - val_accuracy: 0.8918\n",
      "Epoch 74/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3198 - accuracy: 0.8281 - val_loss: 0.2410 - val_accuracy: 0.9035\n",
      "Epoch 75/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3157 - accuracy: 0.8303 - val_loss: 0.2730 - val_accuracy: 0.8203\n",
      "Epoch 76/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3176 - accuracy: 0.8310 - val_loss: 0.2462 - val_accuracy: 0.9158\n",
      "Epoch 77/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3160 - accuracy: 0.8304 - val_loss: 0.2673 - val_accuracy: 0.8362\n",
      "Epoch 78/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3152 - accuracy: 0.8304 - val_loss: 0.2375 - val_accuracy: 0.8991\n",
      "Epoch 79/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3222 - accuracy: 0.8299 - val_loss: 0.2505 - val_accuracy: 0.9113\n",
      "Epoch 80/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3164 - accuracy: 0.8305 - val_loss: 0.2384 - val_accuracy: 0.9007\n",
      "Epoch 81/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3187 - accuracy: 0.8251 - val_loss: 0.2670 - val_accuracy: 0.8505\n",
      "Epoch 82/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3246 - accuracy: 0.8258 - val_loss: 0.2431 - val_accuracy: 0.8682\n",
      "Epoch 83/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3211 - accuracy: 0.8265 - val_loss: 0.2691 - val_accuracy: 0.8481\n",
      "Epoch 84/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3173 - accuracy: 0.8290 - val_loss: 0.2666 - val_accuracy: 0.8507\n",
      "Epoch 85/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3139 - accuracy: 0.8288 - val_loss: 0.2462 - val_accuracy: 0.8586\n",
      "Epoch 86/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3193 - accuracy: 0.8297 - val_loss: 0.2366 - val_accuracy: 0.8741\n",
      "Epoch 87/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3112 - accuracy: 0.8379 - val_loss: 0.2488 - val_accuracy: 0.8571\n",
      "Epoch 88/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3123 - accuracy: 0.8339 - val_loss: 0.2315 - val_accuracy: 0.8898\n",
      "Epoch 89/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3159 - accuracy: 0.8321 - val_loss: 0.2472 - val_accuracy: 0.8594\n",
      "Epoch 90/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3222 - accuracy: 0.8255 - val_loss: 0.2449 - val_accuracy: 0.8602\n",
      "Epoch 91/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8265 - val_loss: 0.2719 - val_accuracy: 0.8525\n",
      "Epoch 92/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3123 - accuracy: 0.8329 - val_loss: 0.2375 - val_accuracy: 0.8682\n",
      "Epoch 93/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3172 - accuracy: 0.8293 - val_loss: 0.2468 - val_accuracy: 0.9126\n",
      "Epoch 94/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3161 - accuracy: 0.8295 - val_loss: 0.2416 - val_accuracy: 0.8664\n",
      "Epoch 95/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3137 - accuracy: 0.8298 - val_loss: 0.2461 - val_accuracy: 0.9071\n",
      "Epoch 96/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3135 - accuracy: 0.8333 - val_loss: 0.2556 - val_accuracy: 0.8531\n",
      "Epoch 97/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3076 - accuracy: 0.8347 - val_loss: 0.2594 - val_accuracy: 0.8473\n",
      "Epoch 98/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3070 - accuracy: 0.8342 - val_loss: 0.2446 - val_accuracy: 0.8594\n",
      "Epoch 99/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3090 - accuracy: 0.8348 - val_loss: 0.2775 - val_accuracy: 0.8499\n",
      "Epoch 100/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3134 - accuracy: 0.8330 - val_loss: 0.2349 - val_accuracy: 0.8854\n",
      "Epoch 101/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3065 - accuracy: 0.8359 - val_loss: 0.2280 - val_accuracy: 0.8886\n",
      "Epoch 102/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3132 - accuracy: 0.8357 - val_loss: 0.2481 - val_accuracy: 0.8858\n",
      "Epoch 103/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3104 - accuracy: 0.8357 - val_loss: 0.2378 - val_accuracy: 0.8662\n",
      "Epoch 104/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3046 - accuracy: 0.8354 - val_loss: 0.2351 - val_accuracy: 0.8668\n",
      "Epoch 105/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3075 - accuracy: 0.8374 - val_loss: 0.2544 - val_accuracy: 0.8551\n",
      "Epoch 106/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3131 - accuracy: 0.8340 - val_loss: 0.2578 - val_accuracy: 0.8533\n",
      "Epoch 107/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3070 - accuracy: 0.8365 - val_loss: 0.2527 - val_accuracy: 0.8561\n",
      "Epoch 108/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3040 - accuracy: 0.8356 - val_loss: 0.2391 - val_accuracy: 0.9037\n",
      "Epoch 109/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3116 - accuracy: 0.8348 - val_loss: 0.2408 - val_accuracy: 0.8634\n",
      "Epoch 110/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3080 - accuracy: 0.8353 - val_loss: 0.2342 - val_accuracy: 0.9117\n",
      "Epoch 111/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3123 - accuracy: 0.8299 - val_loss: 0.2633 - val_accuracy: 0.8465\n",
      "Epoch 112/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3143 - accuracy: 0.8326 - val_loss: 0.2396 - val_accuracy: 0.8646\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3213 - accuracy: 0.8319 - val_loss: 0.2648 - val_accuracy: 0.8523\n",
      "Epoch 114/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3109 - accuracy: 0.8360 - val_loss: 0.2397 - val_accuracy: 0.8644\n",
      "Epoch 115/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3140 - accuracy: 0.8301 - val_loss: 0.2317 - val_accuracy: 0.8783\n",
      "Epoch 116/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3114 - accuracy: 0.8324 - val_loss: 0.2572 - val_accuracy: 0.8535\n",
      "Epoch 117/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3072 - accuracy: 0.8374 - val_loss: 0.2287 - val_accuracy: 0.8932\n",
      "Epoch 118/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3206 - accuracy: 0.8365 - val_loss: 0.2467 - val_accuracy: 0.8890\n",
      "Epoch 119/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3021 - accuracy: 0.8410 - val_loss: 0.2638 - val_accuracy: 0.8533\n",
      "Epoch 120/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3102 - accuracy: 0.8365 - val_loss: 0.2588 - val_accuracy: 0.8533\n",
      "Epoch 121/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3116 - accuracy: 0.8369 - val_loss: 0.2390 - val_accuracy: 0.9178\n",
      "Epoch 122/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3091 - accuracy: 0.8327 - val_loss: 0.2414 - val_accuracy: 0.8620\n",
      "Epoch 123/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3210 - accuracy: 0.8376 - val_loss: 0.2494 - val_accuracy: 0.8620\n",
      "Epoch 124/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3013 - accuracy: 0.8428 - val_loss: 0.2309 - val_accuracy: 0.9172\n",
      "Epoch 125/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3084 - accuracy: 0.8353 - val_loss: 0.2858 - val_accuracy: 0.8499\n",
      "Epoch 126/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: 0.3101 - accuracy: 0.8332 - val_loss: 0.2321 - val_accuracy: 0.9031\n",
      "Epoch 127/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3193 - accuracy: 0.8339 - val_loss: 0.2679 - val_accuracy: 0.8507\n",
      "Epoch 128/150\n",
      "1008/1008 [==============================] - 110s 109ms/step - loss: 0.3126 - accuracy: 0.8324 - val_loss: 0.2803 - val_accuracy: 0.8479\n",
      "Epoch 129/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: 0.3163 - accuracy: 0.8302 - val_loss: 0.2395 - val_accuracy: 0.8692 - loss: 0\n",
      "Epoch 130/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3047 - accuracy: 0.8399 - val_loss: 0.2323 - val_accuracy: 0.8690\n",
      "Epoch 131/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3147 - accuracy: 0.8330 - val_loss: 0.6986 - val_accuracy: 0.7219\n",
      "Epoch 132/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3271 - accuracy: 0.8290 - val_loss: 0.2593 - val_accuracy: 0.8535\n",
      "Epoch 133/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3018 - accuracy: 0.8398 - val_loss: 0.3018 - val_accuracy: 0.8489\n",
      "Epoch 134/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3171 - accuracy: 0.8310 - val_loss: 0.2462 - val_accuracy: 0.8924\n",
      "Epoch 135/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3120 - accuracy: 0.8375 - val_loss: 0.2316 - val_accuracy: 0.9025\n",
      "Epoch 136/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3106 - accuracy: 0.8376 - val_loss: 0.2643 - val_accuracy: 0.8515\n",
      "Epoch 137/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3037 - accuracy: 0.8388 - val_loss: 0.2249 - val_accuracy: 0.8876\n",
      "Epoch 138/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3094 - accuracy: 0.8386 - val_loss: 0.2293 - val_accuracy: 0.8779\n",
      "Epoch 139/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.3182 - accuracy: 0.8330 - val_loss: 0.2526 - val_accuracy: 0.8557\n",
      "Epoch 140/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3172 - accuracy: 0.8319 - val_loss: 0.2481 - val_accuracy: 0.8569\n",
      "Epoch 141/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3156 - accuracy: 0.8334 - val_loss: 0.2333 - val_accuracy: 0.8860\n",
      "Epoch 142/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3175 - accuracy: 0.8317 - val_loss: 0.2435 - val_accuracy: 0.8596\n",
      "Epoch 143/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3109 - accuracy: 0.8391 - val_loss: 0.3114 - val_accuracy: 0.8451\n",
      "Epoch 144/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3072 - accuracy: 0.8356 - val_loss: 0.2259 - val_accuracy: 0.8978\n",
      "Epoch 145/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3162 - accuracy: 0.8309 - val_loss: 0.2354 - val_accuracy: 0.8787\n",
      "Epoch 146/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3053 - accuracy: 0.8362 - val_loss: 0.2620 - val_accuracy: 0.8372\n",
      "Epoch 147/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3090 - accuracy: 0.8406 - val_loss: 0.2315 - val_accuracy: 0.8680\n",
      "Epoch 148/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3083 - accuracy: 0.8373 - val_loss: 0.2239 - val_accuracy: 0.8968\n",
      "Epoch 149/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.3073 - accuracy: 0.8307 - val_loss: 0.2512 - val_accuracy: 0.8573\n",
      "Epoch 150/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.2985 - accuracy: 0.8454 - val_loss: 0.2560 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x271b10378b0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x,y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5ce77ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1s 821us/step - loss: 0.2844 - accuracy: 0.8382\n",
      "accuracy: 83.82%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(x,y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472432fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
